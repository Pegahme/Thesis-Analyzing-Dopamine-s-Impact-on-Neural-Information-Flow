{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c31a5fa4-1169-4e44-aa58-fb4bfc4a59c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import entropy\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from sklearn.decomposition import PCA\n",
    "from kneed import KneeLocator\n",
    "\n",
    "# === PARAMETERS ===\n",
    "FOLDER = Path(\"/lustre/majlepy2/myproject/36files_source_localized\")  # adjust if needed\n",
    "segment_length = 50\n",
    "bins = 30\n",
    "normalize_data = True\n",
    "n_nodes = 68\n",
    "SCALE = 1e12\n",
    "\n",
    "# === OUTPUT ===\n",
    "output_dir = Path(\"/lustre/majlepy2/myproject/50_epochs_tc3d\")\n",
    "output_prefix = \"_68localized_50epochs.npy\"\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Figure path\n",
    "figpath = output_dir / \"group_metrics_50_epochs_segment.png\"\n",
    "\n",
    "# --- FIND FILES ---\n",
    "files = sorted(FOLDER.glob(\"*_label_tc3d.npy\"))\n",
    "print(f\"Found {len(files)} files in {FOLDER}\")\n",
    "\n",
    "# --- METRICS STORAGE ---\n",
    "all_variances, all_entropies, all_pca_scores, valid_files = [], [], [], []\n",
    "\n",
    "# --- PROCESS FILES ---\n",
    "for file in files:\n",
    "    X = np.load(file)\n",
    "    print(f\"\\nLoaded {file.name} with shape {X.shape}\")\n",
    "\n",
    "    if X.shape[0] != n_nodes or X.shape[2] < segment_length:\n",
    "        print(f\"Skipping {file.name} (shape mismatch)\")\n",
    "        continue\n",
    "\n",
    "    X = X * SCALE\n",
    "    if normalize_data:\n",
    "        X = (X - X.mean(axis=(1, 2), keepdims=True)) / (X.std(axis=(1, 2), keepdims=True) + 1e-8)\n",
    "\n",
    "    valid_files.append(file)\n",
    "    window_starts = np.arange(X.shape[2] - segment_length + 1)\n",
    "\n",
    "    subj_vars, subj_ents, subj_pca = [], [], []\n",
    "\n",
    "    for start in window_starts:\n",
    "        segment = X[..., start:start + segment_length]\n",
    "\n",
    "        # --- Variance ---\n",
    "        avg_var = np.mean([np.var(segment[i]) for i in range(X.shape[0])])\n",
    "        subj_vars.append(avg_var)\n",
    "\n",
    "        # --- Entropy ---\n",
    "        node_ents = []\n",
    "        for i in range(X.shape[0]):\n",
    "            values = segment[i].flatten()\n",
    "            hist, _ = np.histogram(np.abs(values), bins=bins, density=True)\n",
    "            probs = hist / np.sum(hist)\n",
    "            probs = probs[probs > 0]\n",
    "            node_ents.append(entropy(probs, base=2))\n",
    "        subj_ents.append(np.mean(node_ents))\n",
    "\n",
    "        # --- PCA Score (Elbow method) ---\n",
    "        reshaped = segment.reshape(X.shape[0], -1)\n",
    "        pca = PCA()\n",
    "        pca.fit(reshaped.T)\n",
    "        explained = pca.explained_variance_ratio_\n",
    "\n",
    "        try:\n",
    "            knee = KneeLocator(\n",
    "                range(1, len(explained) + 1),\n",
    "                explained,\n",
    "                curve=\"convex\",\n",
    "                direction=\"decreasing\"\n",
    "            )\n",
    "            elbow_idx = knee.knee or 1\n",
    "        except Exception:\n",
    "            elbow_idx = 1\n",
    "\n",
    "        pca_score = np.sum(explained[:elbow_idx])\n",
    "        subj_pca.append(pca_score)\n",
    "\n",
    "    all_variances.append(subj_vars)\n",
    "    all_entropies.append(subj_ents)\n",
    "    all_pca_scores.append(subj_pca)\n",
    "\n",
    "# --- FINAL CHECK ---\n",
    "if not all_variances:\n",
    "    raise ValueError(\"No valid data segments found.\")\n",
    "\n",
    "# --- ALIGN ---\n",
    "min_windows = min(len(x) for x in all_variances)\n",
    "V = np.array([x[:min_windows] for x in all_variances])\n",
    "E = np.array([x[:min_windows] for x in all_entropies])\n",
    "P = np.array([x[:min_windows] for x in all_pca_scores])\n",
    "\n",
    "# --- NORMALIZED GROUP METRICS ---\n",
    "group_var, group_ent, group_pca = V.mean(axis=0), E.mean(axis=0), P.mean(axis=0)\n",
    "\n",
    "def normalize(x):\n",
    "    denom = x.max() - x.min()\n",
    "    return (x - x.min()) / denom if denom != 0 else np.zeros_like(x)\n",
    "\n",
    "var_norm, ent_norm, pca_norm = normalize(group_var), normalize(group_ent), normalize(group_pca)\n",
    "combined = (var_norm + ent_norm + pca_norm) / 3\n",
    "\n",
    "# --- SELECT BEST WINDOW ---\n",
    "best_var_idx, best_ent_idx = int(np.argmax(var_norm)), int(np.argmax(ent_norm))\n",
    "best_pca_idx, best_comb_idx = int(np.argmax(pca_norm)), int(np.argmax(combined))\n",
    "\n",
    "# --- PLOT (with matching colors) ---\n",
    "colors = {\"var\": \"tab:blue\", \"ent\": \"tab:orange\", \"pca\": \"tab:green\", \"comb\": \"tab:red\"}\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(var_norm, \"-o\", lw=2, markevery=20, label=\"Variance (normalized)\", color=colors[\"var\"])\n",
    "plt.plot(ent_norm, \"-s\", lw=2, markevery=20, label=\"Entropy (normalized)\", color=colors[\"ent\"])\n",
    "plt.plot(pca_norm, \"-^\", lw=2, markevery=20, label=\"PCA Score (elbow-based)\", color=colors[\"pca\"])\n",
    "plt.plot(combined, \"--\", lw=3, label=\"Combined\", color=colors[\"comb\"])\n",
    "\n",
    "plt.axvline(best_var_idx, linestyle=\":\", lw=1, color=colors[\"var\"], label=f\"Best Variance\")\n",
    "plt.axvline(best_ent_idx, linestyle=\":\", lw=1, color=colors[\"ent\"], label=f\"Best Entropy\")\n",
    "plt.axvline(best_pca_idx, linestyle=\":\", lw=1, color=colors[\"pca\"], label=f\"Best PCA\")\n",
    "plt.axvline(best_comb_idx, linestyle=\"-\", lw=2, color=colors[\"comb\"], label=f\"Best Combined\")\n",
    "\n",
    "# Highlight selected window (best_comb_idx)\n",
    "start, end = best_comb_idx, min(best_comb_idx + segment_length, len(combined))\n",
    "plt.axvspan(start, end, alpha=0.15, color=colors[\"comb\"], label=f\"Selected window [{start}:{end})\")\n",
    "\n",
    "plt.xlabel(\"Window start epoch index\")\n",
    "plt.ylabel(\"Group-level metric (normalized)\")\n",
    "plt.title(\"Group-Level Informative Segment Selection\")\n",
    "plt.grid(True)\n",
    "plt.legend(\n",
    "    loc=\"lower right\",\n",
    "    bbox_to_anchor=(1, 0.19),   # shifted up\n",
    "    fontsize=9,\n",
    "    frameon=True,\n",
    "    ncol=2\n",
    ")\n",
    "plt.tight_layout()\n",
    "\n",
    "# --- SAVE FIGURE ---\n",
    "plt.savefig(figpath, dpi=300, bbox_inches=\"tight\")\n",
    "print(f\"Saved figure to {figpath}\")\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# --- EXTRACT AND SAVE SELECTED SEGMENTS ---\n",
    "chosen_start = best_comb_idx\n",
    "for file in valid_files:\n",
    "    X = np.load(file)\n",
    "    X_sel = X[..., chosen_start:chosen_start + segment_length]\n",
    "\n",
    "    original_stem = file.stem.replace(\"_label_tc3d\", \"\")\n",
    "    output_name = original_stem + output_prefix\n",
    "    output_path = output_dir / output_name\n",
    "\n",
    "    np.save(output_path, X_sel)\n",
    "    print(f\"Saved: {output_path} with shape {X_sel.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09f6c0e4-4f79-45b5-8fa1-06a8d1810f98",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
