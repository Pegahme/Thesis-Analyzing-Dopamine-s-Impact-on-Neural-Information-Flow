{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "18425892-6b48-4c20-bc2e-b87cc5844f22",
   "metadata": {},
   "source": [
    "# KSG Results Aggregation\n",
    "\n",
    "This pipeline combines the per-target **KSG estimator** results (GPU/OpenCL) into session-level and group-level datasets.\n",
    "\n",
    "## Workflow\n",
    "\n",
    "1. **Per-target results**\n",
    "   - Each `(subject, session, target)` produces a `.pkl` result file.  \n",
    "   - Expected: **23 results per session** (one per target node).  \n",
    "\n",
    "2. **Session-level combination**\n",
    "   - Check each `sub-*/ses-*` folder contains exactly 23 `.pkl` files.  \n",
    "   - Load all per-target results.  \n",
    "   - Clean per-target settings (e.g., `target`, `filename_ckp`) to avoid conflicts.  \n",
    "   - Combine into a `ResultsNetworkInference` object.  \n",
    "   - Save as:  \n",
    "     ```\n",
    "     sub-XXX_ses-YYY_combined_ksg.pkl\n",
    "     ```\n",
    "\n",
    "3. **Group-level aggregation**\n",
    "   - Metadata (`subject_session_metadata.csv`) provides group labels.  \n",
    "   - Collect all session-level results per group.  \n",
    "   - Save one mega-`.pkl` per group:  \n",
    "     ```\n",
    "     Healthy_ksg_all_sessions.pkl\n",
    "     PD-off_ksg_all_sessions.pkl\n",
    "     PD-on_ksg_all_sessions.pkl\n",
    "     ```\n",
    "\n",
    "4. **Summary CSV**\n",
    "   - Generate `ksg_results_summary.csv` listing subject, session, group, and file paths.  \n",
    "\n",
    "## Outputs\n",
    "\n",
    "- **Session combined files:** one `.pkl` per `(subject, session)`  \n",
    "- **Group combined files:** one `.pkl` per group  \n",
    "- **CSV summary:** `ksg_results_summary.csv`  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "732d69d8-c9bb-4c3d-b3b4-67d67ca4b66b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "import pandas as pd\n",
    "from idtxl.results import ResultsNetworkInference\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "# 1. Path setup\n",
    "# ----------------------------------------------------------------------\n",
    "BASE_DIR = Path(\"/lustre/majlepy2/myproject\")\n",
    "RESULTS_DIR = BASE_DIR / \"Results\"\n",
    "ksg_source_dir = BASE_DIR / \"ksg_mte_50\"\n",
    "\n",
    "ksg_combined_dir = RESULTS_DIR / \"ksg_results\"\n",
    "ksg_combined_dir.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "# 2. Load metadata (for cross-checking)\n",
    "# ----------------------------------------------------------------------\n",
    "meta = pd.read_csv(BASE_DIR / \"subject_session_metadata.csv\")\n",
    "meta['sub_ses'] = meta['subject'] + '/' + meta['session']\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "# 3. Identify session dirs with 23 target results\n",
    "# ----------------------------------------------------------------------\n",
    "session_dirs = []\n",
    "for subses_dir in sorted(ksg_source_dir.glob(\"sub-*/ses-*\")):\n",
    "    pkl_files = list(subses_dir.glob(\"*.pkl\"))\n",
    "    if len(pkl_files) == 23:\n",
    "        session_dirs.append(subses_dir)\n",
    "    else:\n",
    "        print(f\"Skipping {subses_dir}: found {len(pkl_files)} pkl files (expected 23)\")\n",
    "print(f\"Found {len(session_dirs)} sessions with 23 targets.\")\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "# 4. Combine 23 per-target results into one session object\n",
    "# ----------------------------------------------------------------------\n",
    "for subses_dir in session_dirs:\n",
    "    subj = subses_dir.parts[-2]\n",
    "    sess = subses_dir.parts[-1]\n",
    "    combined_name = f\"{subj}_{sess}_combined_ksg.pkl\"\n",
    "    combined_path = ksg_combined_dir / combined_name\n",
    "\n",
    "    pkl_files = sorted(subses_dir.glob(\"*.pkl\"))\n",
    "    results = []\n",
    "    for pf in pkl_files:\n",
    "        with open(pf, \"rb\") as f:\n",
    "            obj = pickle.load(f)\n",
    "            # Drop per-target settings not needed for session-level merge\n",
    "            for k in ['target', 'filename_ckp', 'write_ckp', 'loglevel']:\n",
    "                obj.settings.pop(k, None)\n",
    "            results.append(obj)\n",
    "\n",
    "    example = results[0]\n",
    "    combined_result = ResultsNetworkInference(\n",
    "        n_nodes=example.data_properties['n_nodes'],\n",
    "        n_realisations=example.data_properties['n_realisations'],\n",
    "        normalised=example.data_properties['normalised'],\n",
    "    )\n",
    "    combined_result.combine_results(*results)\n",
    "\n",
    "    with open(combined_path, \"wb\") as f:\n",
    "        pickle.dump(combined_result, f)\n",
    "    print(f\"Combined and saved: {combined_path}\")\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "# 5. Validate one combined file\n",
    "# ----------------------------------------------------------------------\n",
    "with open(combined_path, \"rb\") as f:\n",
    "    comb = pickle.load(f)\n",
    "print(\"Combined object type:\", type(comb))\n",
    "print(\"Targets analyzed:\", comb.targets_analysed)\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "# 6. Group aggregation and summary export\n",
    "# ----------------------------------------------------------------------\n",
    "ksg_dir = RESULTS_DIR / \"ksg_results\"\n",
    "meta = pd.read_csv(\"/lustre/majlepy2/myproject/subject_session_metadata.csv\")\n",
    "meta['sub_ses'] = meta['subject'] + '_' + meta['session']\n",
    "group_dict = dict(zip(meta['sub_ses'], meta['group']))\n",
    "\n",
    "combined_files = sorted(ksg_dir.glob(\"*_combined_ksg.pkl\"))\n",
    "\n",
    "group_results = {}     # { group_name: [list of session Results objects] }\n",
    "summary_rows = []\n",
    "\n",
    "for f in combined_files:\n",
    "    fname = f.name\n",
    "    try:\n",
    "        stem = fname.replace(\"_combined_ksg.pkl\", \"\")\n",
    "        subj, sess = stem.split(\"_\", 1)\n",
    "        sub_ses = f\"{subj}_{sess}\"\n",
    "    except Exception as e:\n",
    "        print(f\"Skipping {fname}: couldn't parse subject/session ({e})\")\n",
    "        continue\n",
    "\n",
    "    group = group_dict.get(sub_ses)\n",
    "    if group is None:\n",
    "        print(f\"WARNING: {sub_ses} not found in metadata.\")\n",
    "        continue\n",
    "\n",
    "    with open(f, \"rb\") as pf:\n",
    "        res = pickle.load(pf)\n",
    "\n",
    "    group_results.setdefault(group, []).append(res)\n",
    "    summary_rows.append({\n",
    "        \"file\": str(f),\n",
    "        \"subject\": subj,\n",
    "        \"session\": sess,\n",
    "        \"group\": group\n",
    "    })\n",
    "\n",
    "for group, results_list in group_results.items():\n",
    "    out_path = ksg_dir / f\"{group}_ksg_all_sessions.pkl\"\n",
    "    with open(out_path, \"wb\") as pf:\n",
    "        pickle.dump(results_list, pf)\n",
    "    print(f\"Saved {group}: {out_path} ({len(results_list)} sessions)\")\n",
    "\n",
    "summary_df = pd.DataFrame(summary_rows)\n",
    "summary_csv = ksg_dir / \"ksg_results_summary.csv\"\n",
    "summary_df.to_csv(summary_csv, index=False)\n",
    "print(f\"Saved session-to-group mapping: {summary_csv}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
