{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dec1db8d-47d2-470e-9ace-ca93ce187636",
   "metadata": {},
   "source": [
    "# Extract adjacency matrices per session (Gaussian)\n",
    "From each `*_combined_gauss.pkl` (one per subject/session), extract adjacency in three forms:\n",
    "- **binary** (edge present/absent),\n",
    "- **max_p_lag** (lag at max p),\n",
    "- **max_te_lag** (lag at max TE).  \n",
    "Save each as `.npy` next to the combined `.pkl`. Toggle FDR if desired.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49d0d706-95d0-4691-a6d9-09bbc7e5c0fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "\n",
    "# --- Paths ---\n",
    "gauss_dir = Path('/lustre/majlepy2/myproject/Results/gauss_results')\n",
    "\n",
    "# Session-level combined results (.pkl)\n",
    "combined_files = sorted(gauss_dir.glob(\"*_combined_gauss.pkl\"))\n",
    "print(f\"Found {len(combined_files)} combined session files.\")\n",
    "\n",
    "# Toggle FDR if needed for adjacency extraction (False = raw IDTxl results)\n",
    "USE_FDR = False\n",
    "\n",
    "# --- Extract adjacency matrices from each combined session ---\n",
    "for file in combined_files:\n",
    "    with open(file, 'rb') as f:\n",
    "        res = pickle.load(f)\n",
    "\n",
    "    # Extract adjacency matrices in different representations\n",
    "    adj_binary     = np.array(res.get_adjacency_matrix('binary',     fdr=USE_FDR)).astype(np.uint8)\n",
    "    adj_max_p_lag  = np.array(res.get_adjacency_matrix('max_p_lag',  fdr=USE_FDR)).astype(float)\n",
    "    adj_max_te_lag = np.array(res.get_adjacency_matrix('max_te_lag', fdr=USE_FDR)).astype(float)\n",
    "\n",
    "    # Save each adjacency matrix as .npy next to the .pkl\n",
    "    base = file.with_suffix('')  # drop .pkl\n",
    "    np.save(base.with_name(base.name + '_binary.npy'),     adj_binary)\n",
    "    np.save(base.with_name(base.name + '_max_p_lag.npy'),  adj_max_p_lag)\n",
    "    np.save(base.with_name(base.name + '_max_te_lag.npy'), adj_max_te_lag)\n",
    "\n",
    "    print(f\"Saved matrices for {file.name}\")\n",
    "\n",
    "print(\"All session adjacency matrices extracted and saved as .npy (binary, max_p_lag, max_te_lag).\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0618138b-20bf-45ba-97bd-373fbd642337",
   "metadata": {},
   "source": [
    "# Build group-level summaries (Gaussian)\n",
    "Use `subject_session_metadata.csv` to map sessions to groups.  \n",
    "For each group:\n",
    "- Stack **binary** matrices → fraction of sessions with edge (**edge_presence**).\n",
    "- Stack **max_p_lag** matrices → **mode lag** where the edge exists.  \n",
    "Save per-group arrays.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6520f0af-7389-4d72-bf4f-8a26f10faa77",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from collections import Counter\n",
    "\n",
    "# --- Paths ---\n",
    "gauss_dir = Path('/lustre/majlepy2/myproject/Results/gauss_results')\n",
    "meta = pd.read_csv('/lustre/majlepy2/myproject/subject_session_metadata.csv')\n",
    "meta['sub_ses'] = meta['subject'] + '_' + meta['session']\n",
    "\n",
    "# Build lookup: sub_ses -> group\n",
    "group_dict = dict(zip(meta['sub_ses'], meta['group']))\n",
    "\n",
    "# Find all per-session binary and lag matrices (Gaussian)\n",
    "binary_files = sorted(gauss_dir.glob(\"*_gauss_binary.npy\"))\n",
    "lag_files = sorted(gauss_dir.glob(\"*_gauss_max_p_lag.npy\"))\n",
    "assert len(binary_files) == len(lag_files)\n",
    "\n",
    "group_to_binary = {}\n",
    "group_to_lags = {}\n",
    "\n",
    "# --- Assign each session's matrices to its group ---\n",
    "for bin_file, lag_file in zip(binary_files, lag_files):\n",
    "    base = bin_file.name.replace('_gauss_binary.npy', '')\n",
    "    # Remove trailing '_combined' if present to match metadata key format\n",
    "    if base.endswith('_combined'):\n",
    "        base = base[:-9]\n",
    "    sub_ses = base\n",
    "    group = group_dict.get(sub_ses)\n",
    "    if group is None:\n",
    "        print(f\"WARNING: {sub_ses} not found in metadata.\")\n",
    "        continue\n",
    "\n",
    "    # Load matrices\n",
    "    adj_binary = np.load(bin_file)\n",
    "    adj_lag = np.load(lag_file)\n",
    "\n",
    "    # Append to group collections\n",
    "    group_to_binary.setdefault(group, []).append(adj_binary)\n",
    "    group_to_lags.setdefault(group, []).append(adj_lag)\n",
    "\n",
    "print(\"Session matrices loaded and grouped by experimental group.\")\n",
    "\n",
    "# --- Compute group-level summaries ---\n",
    "results = {}\n",
    "for group in group_to_binary:\n",
    "    binaries = np.stack(group_to_binary[group], axis=0)  # shape: (n_sessions, n_nodes, n_nodes)\n",
    "    lags = np.stack(group_to_lags[group], axis=0)        # shape: (n_sessions, n_nodes, n_nodes)\n",
    "    n_sessions = binaries.shape[0]\n",
    "\n",
    "    # Edge presence = fraction of sessions with edge present\n",
    "    edge_presence = binaries.mean(axis=0)\n",
    "\n",
    "    # Lag summary = most common lag per edge (NaN if edge absent across sessions)\n",
    "    lag_summary = np.full(binaries.shape[1:], np.nan)\n",
    "    for i in range(binaries.shape[1]):\n",
    "        for j in range(binaries.shape[2]):\n",
    "            lags_present = lags[:, i, j][binaries[:, i, j] == 1]\n",
    "            if len(lags_present) > 0:\n",
    "                most_common = Counter(lags_present).most_common(1)[0][0]\n",
    "                lag_summary[i, j] = most_common\n",
    "\n",
    "    results[group] = {\n",
    "        \"edge_presence\": edge_presence,\n",
    "        \"lag_summary\": lag_summary,\n",
    "        \"n_sessions\": n_sessions,\n",
    "    }\n",
    "    print(f\"Gaussian {group}: {n_sessions} sessions, edge_presence matrix shape: {edge_presence.shape}\")\n",
    "\n",
    "# --- Save per-group summaries ---\n",
    "for group, group_results in results.items():\n",
    "    np.save(gauss_dir / f\"{group}_gauss_edge_presence.npy\", group_results[\"edge_presence\"])\n",
    "    np.save(gauss_dir / f\"{group}_gauss_lag_summary.npy\", group_results[\"lag_summary\"])\n",
    "    print(f\"Saved Gaussian summary arrays for {group}\")\n",
    "\n",
    "print(\"Gaussian group-level aggregation complete.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77ee10fc-7cf1-4829-a0a1-ab943083ba9a",
   "metadata": {},
   "source": [
    "# Visualize group-level heatmaps (Gaussian)\n",
    "For each group:\n",
    "- **Heatmap 1**: edge presence fraction (0–1).  \n",
    "- **Heatmap 2**: most common lag (masked if presence < threshold).  \n",
    "Figures are saved as PNGs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fa44140-f4ee-4569-8471-58fe5ec9b0e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "\n",
    "# --- Paths ---\n",
    "gauss_dir = Path('/lustre/majlepy2/myproject/Results/gauss_results')\n",
    "out_dir = Path('/home/majlepy2/myproject')\n",
    "out_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# --- Config ---\n",
    "groups = ['healthy', 'PD-on', 'PD-off']\n",
    "est_label = \"Gaussian\"\n",
    "presence_threshold = 0.70  # visualization threshold\n",
    "\n",
    "# --- Generate heatmaps per group ---\n",
    "for group in groups:\n",
    "    print(f\"\\n=== {group} ===\")\n",
    "    edge_file = gauss_dir / f\"{group}_edge_presence.npy\"\n",
    "    lag_file  = gauss_dir / f\"{group}_lag_summary.npy\"\n",
    "\n",
    "    if not edge_file.exists():\n",
    "        print(f\"Missing: {edge_file}\")\n",
    "        continue\n",
    "    if not lag_file.exists():\n",
    "        print(f\"Missing: {lag_file}\")\n",
    "        continue\n",
    "\n",
    "    edge_presence = np.load(edge_file)\n",
    "    lag_summary   = np.load(lag_file)\n",
    "\n",
    "    # Mask lag values where edge presence < threshold\n",
    "    lag_display = np.array(lag_summary, dtype=float)\n",
    "    lag_display[edge_presence < presence_threshold] = np.nan\n",
    "\n",
    "    # --- Create figure with 2 panels ---\n",
    "    fig, axs = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "    # Panel 1 — Edge presence fraction\n",
    "    sns.heatmap(\n",
    "        edge_presence, ax=axs[0], cmap=\"Blues\", vmin=0, vmax=1,\n",
    "        cbar_kws={'label': 'Fraction of sessions (edge present)'}\n",
    "    )\n",
    "    axs[0].set_title(f\"{group} – {est_label}: Edge Presence Fraction\")\n",
    "    axs[0].set_xlabel(\"Target Node\")\n",
    "    axs[0].set_ylabel(\"Source Node\")\n",
    "\n",
    "    # Panel 2 — Most common lag (only if presence ≥ threshold)\n",
    "    sns.heatmap(\n",
    "        lag_display, ax=axs[1], cmap=\"viridis\",\n",
    "        cbar_kws={'label': f\"Most Common Lag (shown where presence ≥ {int(presence_threshold*100)}%)\"}\n",
    "    )\n",
    "    axs[1].set_title(f\"{group} – {est_label}: Most Common Lag (edges with ≥{int(presence_threshold*100)}% presence)\")\n",
    "    axs[1].set_xlabel(\"Target Node\")\n",
    "    axs[1].set_ylabel(\"Source Node\")\n",
    "\n",
    "    fig.tight_layout()\n",
    "\n",
    "    # Save to PNG\n",
    "    out_png = out_dir / f\"{group.replace(' ', '_')}_{est_label.lower()}_adj_{int(presence_threshold*100)}.png\"\n",
    "    fig.savefig(out_png, dpi=200, bbox_inches='tight')\n",
    "    plt.show()  # or close if running headless\n",
    "    # plt.close(fig)\n",
    "    print(f\"Saved: {out_png}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
