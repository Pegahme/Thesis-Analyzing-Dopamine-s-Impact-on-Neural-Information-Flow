{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "85a6e8ae-2c5c-4115-87de-550621a03730",
   "metadata": {},
   "source": [
    "# Build Gaussian results, compute group presence, counts, lag summaries, and overlap (recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c3028bdf-ece5-474c-8d29-a1e61656b1dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gaussian: found 36 sessions with 23 targets.\n",
      "Gaussian: 36 combined session files.\n",
      "[presence] healthy: shape=(23, 23)\n",
      "[presence] PD-off: shape=(23, 23)\n",
      "[presence] PD-on: shape=(23, 23)\n",
      "   estimator    group  threshold  robust_edges\n",
      "0        KSG  healthy         50           477\n",
      "1        KSG  healthy         70           331\n",
      "2        KSG  healthy         90           117\n",
      "3        KSG   PD-off         50           486\n",
      "4        KSG   PD-off         70           296\n",
      "5        KSG   PD-off         90            84\n",
      "6        KSG    PD-on         50           477\n",
      "7        KSG    PD-on         70           331\n",
      "8        KSG    PD-on         90           140\n",
      "9   Gaussian  healthy         50            81\n",
      "10  Gaussian  healthy         70             6\n",
      "11  Gaussian  healthy         90             1\n",
      "12  Gaussian   PD-off         50           105\n",
      "13  Gaussian   PD-off         70             9\n",
      "14  Gaussian   PD-off         90             1\n",
      "15  Gaussian    PD-on         50           110\n",
      "16  Gaussian    PD-on         70            12\n",
      "17  Gaussian    PD-on         90             2\n",
      "[fig] /home/majlepy2/myproject/Step-wise/figs/Comparison/robust_edges_thresholds_healthy.png\n",
      "[fig] /home/majlepy2/myproject/Step-wise/figs/Comparison/robust_edges_thresholds_PD-off.png\n",
      "[fig] /home/majlepy2/myproject/Step-wise/figs/Comparison/robust_edges_thresholds_PD-on.png\n",
      "estimator   group  threshold  n_robust_edges  count_50  count_100  count_150  count_200  count_250  width_bins  median_ms     iqr\n",
      " Gaussian healthy         70               6         6          0          0          0          0           1       50.0 [50–50]\n",
      " Gaussian  PD-off         70               9         7          2          0          0          0           2       50.0 [50–50]\n",
      " Gaussian   PD-on         70              12        11          0          0          1          0           2       50.0 [50–50]\n",
      "[csv] /home/majlepy2/myproject/Step-wise/Comparison/lag_repertoire_Gaussian_thr70.csv\n",
      "estimator   group  threshold  n_robust_edges  count_50  count_100  count_150  count_200  count_250  width_bins  median_ms     iqr\n",
      " Gaussian healthy         90               1         1          0          0          0          0           1       50.0 [50–50]\n",
      " Gaussian  PD-off         90               1         1          0          0          0          0           1       50.0 [50–50]\n",
      " Gaussian   PD-on         90               2         2          0          0          0          0           1       50.0 [50–50]\n",
      "[csv] /home/majlepy2/myproject/Step-wise/Comparison/lag_repertoire_Gaussian_thr90.csv\n",
      "     group  threshold  consensus_edges  ksg_robust  gauss_robust  \\\n",
      "0  healthy         70                5         331             6   \n",
      "1   PD-off         70                9         296             9   \n",
      "2    PD-on         70               11         331            12   \n",
      "3  healthy         90                0         117             1   \n",
      "4   PD-off         90                1          84             1   \n",
      "5    PD-on         90                2         140             2   \n",
      "\n",
      "   gauss_recall_of_ksg  \n",
      "0                0.015  \n",
      "1                0.030  \n",
      "2                0.033  \n",
      "3                0.000  \n",
      "4                0.012  \n",
      "5                0.014  \n"
     ]
    }
   ],
   "source": [
    "# ============================\n",
    "# Gaussian pipeline + KSG vs Gaussian comparison\n",
    "# Reproducible analysis used in \"Nonlinear vs. linear estimators\"\n",
    "#\n",
    "# What this cell does:\n",
    "#   1) (Optional) Combines per-target Gaussian IDTxl Results (23 .pkl per session) into\n",
    "#      one session-level Results object per session.\n",
    "#   2) Extracts session-level Gaussian adjacency matrices:\n",
    "#        - binary (edge present per session)\n",
    "#        - max_te_lag (modal TE delay per edge per session)\n",
    "#      and saves them as .npy.\n",
    "#   3) Builds group-level presence matrices (fraction of sessions with the edge).\n",
    "#   4) Loads previously produced KSG group presence matrices.\n",
    "#   5) Derives robust-edge counts at 50/70/90% for KSG and Gaussian; saves CSV and plots.\n",
    "#   6) Summarizes Gaussian lag repertoires for robust edges at 70% and 90%; saves CSVs.\n",
    "#   7) Computes estimator overlap at 70% and 90% (CONSENSUS and Gaussian RECALL of KSG).\n",
    "#\n",
    "# Notes:\n",
    "#   - No across-edge FDR is applied here (fdr=False), matching the manuscript.\n",
    "#   - Lags are assumed to be coded as bins 1..5. These are converted to ms by ×50.\n",
    "#   - KSG presence matrices must already exist in KSG_RESULTS (produced earlier in the project).\n",
    "#   - Figure outputs are written under OUTBASE; copy/symlink to your LaTeX figure folder as needed.\n",
    "# ============================\n",
    "\n",
    "from pathlib import Path\n",
    "import re, pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "\n",
    "# ---------- Paths (EDIT GAUSS_SOURCE_DIR to your local location if needed) ----------\n",
    "BASE            = Path(\"/lustre/majlepy2/myproject\")\n",
    "RESULTS         = BASE / \"Results\"\n",
    "KSG_RESULTS     = RESULTS / \"ksg_results\"\n",
    "GAUSS_SOURCE_DIR= BASE / \"gaussian_mte_50\"         # <-- location of per-target Gaussian Results .pkl files (23 per session)\n",
    "GAUSS_RESULTS   = RESULTS / \"gauss_results\"        # derived Gaussian arrays and combined pickles are saved here\n",
    "GAUSS_RESULTS.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "META_CSV        = BASE / \"subject_session_metadata.csv\"\n",
    "\n",
    "OUTBASE         = Path(\"/home/majlepy2/myproject/Step-wise\")\n",
    "FIGS            = OUTBASE / \"figs\" / \"Comparison\"  # robust-edge count figures (per group)\n",
    "FIGS.mkdir(parents=True, exist_ok=True)\n",
    "OUTCSV          = OUTBASE / \"Comparison\"           # CSV outputs for counts, lags, overlap\n",
    "OUTCSV.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# ---------- Metadata: map 'subject_session' -> group (healthy / PD-off / PD-on) ----------\n",
    "meta = pd.read_csv(META_CSV)\n",
    "meta[\"sub_ses\"] = meta[\"subject\"] + \"_\" + meta[\"session\"]\n",
    "subses_to_group = dict(zip(meta[\"sub_ses\"], meta[\"group\"]))\n",
    "\n",
    "# ---------- Helper: combine per-target Gaussian Results into one session-level Results ----------\n",
    "def combine_gaussian_sessions():\n",
    "    \"\"\"\n",
    "    For each session directory under GAUSS_SOURCE_DIR (e.g., sub-XXX/ses-YY) that contains\n",
    "    exactly 23 IDTxl Results .pkl files (one per target), load them and combine into a single\n",
    "    ResultsNetworkInference object, then save as *_combined_gauss.pkl in GAUSS_RESULTS.\n",
    "\n",
    "    Skips sessions with a different number of .pkl files and prints a note.\n",
    "    \"\"\"\n",
    "    session_dirs = []\n",
    "    for subses_dir in sorted(GAUSS_SOURCE_DIR.glob(\"sub-*/ses-*\")):\n",
    "        pkl_files = list(subses_dir.glob(\"*.pkl\"))\n",
    "        if len(pkl_files) == 23:\n",
    "            session_dirs.append(subses_dir)\n",
    "        else:\n",
    "            print(f\"[skip] {subses_dir} has {len(pkl_files)} pkls (need 23)\")\n",
    "    print(f\"Gaussian: found {len(session_dirs)} sessions with 23 targets.\")\n",
    "\n",
    "    for subses_dir in session_dirs:\n",
    "        subj = subses_dir.parts[-2]\n",
    "        sess = subses_dir.parts[-1]\n",
    "        out_pkl = GAUSS_RESULTS / f\"{subj}_{sess}_combined_gauss.pkl\"\n",
    "        if out_pkl.exists():\n",
    "            continue\n",
    "        from idtxl.results import ResultsNetworkInference\n",
    "        results = []\n",
    "        for pf in sorted(subses_dir.glob(\"*.pkl\")):\n",
    "            with open(pf, \"rb\") as f:\n",
    "                obj = pickle.load(f)\n",
    "                # prune non-essential settings keys to keep combined Results clean\n",
    "                for k in ['target','filename_ckp','write_ckp','loglevel']:\n",
    "                    obj.settings.pop(k, None)\n",
    "                results.append(obj)\n",
    "        example = results[0]\n",
    "        comb = ResultsNetworkInference(\n",
    "            n_nodes=example.data_properties['n_nodes'],\n",
    "            n_realisations=example.data_properties['n_realisations'],\n",
    "            normalised=example.data_properties['normalised'],\n",
    "        )\n",
    "        comb.combine_results(*results)\n",
    "        with open(out_pkl, \"wb\") as f:\n",
    "            pickle.dump(comb, f)\n",
    "        print(f\"[combined] {out_pkl}\")\n",
    "\n",
    "# Combine (idempotent). If GAUSS_SOURCE_DIR is absent, assume combined pickles exist already.\n",
    "if GAUSS_SOURCE_DIR.exists():\n",
    "    combine_gaussian_sessions()\n",
    "else:\n",
    "    print(f\"[WARN] GAUSS_SOURCE_DIR not found ({GAUSS_SOURCE_DIR}); assuming combined pickles exist.\")\n",
    "\n",
    "# ---------- Extract Gaussian adjacencies to .npy (binary + max_te_lag), no FDR ----------\n",
    "def get_adj(res, weights, fdr=False):\n",
    "    # Thin wrapper around IDTxl API to return a numpy array.\n",
    "    return np.array(res.get_adjacency_matrix(weights, fdr=fdr))\n",
    "\n",
    "gauss_pkls = sorted(GAUSS_RESULTS.glob(\"sub-*_*_combined_gauss.pkl\"))\n",
    "print(f\"Gaussian: {len(gauss_pkls)} combined session files.\")\n",
    "\n",
    "for f in gauss_pkls:\n",
    "    stem = f.stem.replace(\"_combined_gauss\", \"\")  # sub-XXX_ses-YY\n",
    "    out_bin = GAUSS_RESULTS / f\"{stem}_gauss_binary.npy\"\n",
    "    out_lag = GAUSS_RESULTS / f\"{stem}_gauss_max_te_lag.npy\"\n",
    "    if out_bin.exists() and out_lag.exists():\n",
    "        continue\n",
    "    with open(f, \"rb\") as pf:\n",
    "        res = pickle.load(pf)\n",
    "    # No across-edge FDR; per-edge inference threshold; see manuscript\n",
    "    A = get_adj(res, \"binary\",    fdr=False).astype(np.uint8)\n",
    "    L = get_adj(res, \"max_te_lag\",fdr=False).astype(float)\n",
    "    np.fill_diagonal(A, 0)\n",
    "    np.fill_diagonal(L, np.nan)\n",
    "    np.save(out_bin, A)\n",
    "    np.save(out_lag, L)\n",
    "    print(f\"[saved] {out_bin.name}, {out_lag.name}\")\n",
    "\n",
    "# ---------- Group-level presence (Gaussian): fraction of sessions with edge present ----------\n",
    "def group_presence_gauss():\n",
    "    \"\"\"\n",
    "    Loads all *_gauss_binary.npy per session, groups them by cohort, and computes the mean\n",
    "    across sessions to obtain group-level edge-presence matrices (values in [0,1]).\n",
    "    \"\"\"\n",
    "    groups = {\"healthy\": [], \"PD-off\": [], \"PD-on\": []}\n",
    "    for bin_path in sorted(GAUSS_RESULTS.glob(\"sub-*_*_gauss_binary.npy\")):\n",
    "        stem = bin_path.name.replace(\"_gauss_binary.npy\",\"\")  # sub-XXX_ses-YY\n",
    "        m = re.match(r\"(sub-\\d+)_([^_]+)\", stem)\n",
    "        if not m: \n",
    "            continue\n",
    "        sub_ses = f\"{m.group(1)}_{m.group(2)}\"\n",
    "        g = subses_to_group.get(sub_ses)\n",
    "        if g not in groups:\n",
    "            continue\n",
    "        A = np.load(bin_path).astype(np.uint8)\n",
    "        groups[g].append(A)\n",
    "    pres = {}\n",
    "    for g, mats in groups.items():\n",
    "        if not mats:\n",
    "            raise RuntimeError(f\"No Gaussian binaries for group {g}\")\n",
    "        M = np.stack(mats, axis=0)\n",
    "        P = M.mean(axis=0)          # fraction of sessions with edge present\n",
    "        np.fill_diagonal(P, 0.0)\n",
    "        np.save(GAUSS_RESULTS / f\"{g}_gauss_edge_presence.npy\", P)\n",
    "        pres[g] = P\n",
    "        print(f\"[presence] {g}: shape={P.shape}\")\n",
    "    return pres\n",
    "\n",
    "G_presence = group_presence_gauss()\n",
    "\n",
    "# ---------- Load KSG presence (must be produced earlier in the pipeline) ----------\n",
    "K_presence = {\n",
    "    \"healthy\": np.load(KSG_RESULTS / \"healthy_ksg_edge_presence.npy\"),\n",
    "    \"PD-off\":  np.load(KSG_RESULTS / \"PD-off_ksg_edge_presence.npy\"),\n",
    "    \"PD-on\":   np.load(KSG_RESULTS / \"PD-on_ksg_edge_presence.npy\"),\n",
    "}\n",
    "\n",
    "# ---------- Robust-edge counts vs threshold, per estimator (50/70/90%) ----------\n",
    "THRS = [0.50, 0.70, 0.90]\n",
    "rows = []\n",
    "for est, pres in [(\"KSG\", K_presence), (\"Gaussian\", G_presence)]:\n",
    "    for g in [\"healthy\",\"PD-off\",\"PD-on\"]:\n",
    "        P = pres[g]\n",
    "        N = P.shape[0]\n",
    "        diag = np.eye(N, dtype=bool)\n",
    "        for thr in THRS:\n",
    "            R = (P >= thr) & (~diag)\n",
    "            rows.append({\n",
    "                \"estimator\": est,\n",
    "                \"group\": g,\n",
    "                \"threshold\": int(thr*100),\n",
    "                \"robust_edges\": int(R.sum())\n",
    "            })\n",
    "df_counts = pd.DataFrame(rows)\n",
    "df_counts.to_csv(OUTCSV / \"robust_edge_counts_ksg_vs_gaussian.csv\", index=False)\n",
    "print(df_counts)\n",
    "\n",
    "# ---------- Plot: robust edges vs threshold (one PNG per group; KSG vs Gaussian) ----------\n",
    "def plot_counts(df):\n",
    "    \"\"\"\n",
    "    Saves bar plots for each group showing # robust edges for KSG vs Gaussian at 50/70/90% presence.\n",
    "    \"\"\"\n",
    "    for g in [\"healthy\",\"PD-off\",\"PD-on\"]:\n",
    "        sub = df[df.group==g].pivot(index=\"threshold\", columns=\"estimator\", values=\"robust_edges\")\n",
    "        sub = sub.loc[sorted(sub.index)]\n",
    "        fig, ax = plt.subplots(figsize=(5,3), dpi=150)\n",
    "        sub.plot(kind=\"bar\", ax=ax)\n",
    "        ax.set_title(f\"Robust edges vs threshold — {g}\")\n",
    "        ax.set_ylabel(\"# robust edges\")\n",
    "        ax.set_xlabel(\"Presence threshold (%)\")\n",
    "        fig.tight_layout()\n",
    "        fig.savefig(FIGS / f\"robust_edges_thresholds_{g}.png\", bbox_inches=\"tight\")\n",
    "        plt.close(fig)\n",
    "        print(f\"[fig] {FIGS / f'robust_edges_thresholds_{g}.png'}\")\n",
    "\n",
    "plot_counts(df_counts)\n",
    "\n",
    "# ---------- Lag histograms for Gaussian robust edges (parallel to the KSG timing section) ----------\n",
    "def to_ms(arr):\n",
    "    \"\"\"\n",
    "    Convert lag bins (1..5) to ms by ×50 if they look like small integers; otherwise leave as-is.\n",
    "    \"\"\"\n",
    "    a = arr.copy()\n",
    "    finite = np.isfinite(a)\n",
    "    if finite.any() and np.nanmax(a[finite]) <= 10:\n",
    "        a[finite] = a[finite] * 50.0\n",
    "    return a\n",
    "\n",
    "def modal_lag_per_edge(session_npy_prefix=\"_gauss\"):\n",
    "    \"\"\"\n",
    "    For each group, compute the per-edge modal lag (ms) across sessions, counting only sessions\n",
    "    where the edge is present (binary==1). Diagonals are ignored. Returns dict[group] -> (N x N).\n",
    "    \"\"\"\n",
    "    groups = {\"healthy\": [], \"PD-off\": [], \"PD-on\": []}\n",
    "    for bin_path in sorted(GAUSS_RESULTS.glob(f\"sub-*_*{session_npy_prefix}_binary.npy\")):\n",
    "        stem = bin_path.name.replace(f\"{session_npy_prefix}_binary.npy\",\"\").rstrip(\"_\")\n",
    "        parts = stem.split(\"_\")\n",
    "        sub_ses = \"_\".join(parts[:2])\n",
    "        g = subses_to_group.get(sub_ses)\n",
    "        if g not in groups: \n",
    "            continue\n",
    "        A = np.load(bin_path).astype(np.uint8)\n",
    "        L = np.load(GAUSS_RESULTS / f\"{stem}{session_npy_prefix}_max_te_lag.npy\").astype(float)\n",
    "        groups[g].append((A,L))\n",
    "    out = {}\n",
    "    for g, items in groups.items():\n",
    "        if not items:\n",
    "            raise RuntimeError(f\"No sessions for {g} (Gaussian).\")\n",
    "        N = items[0][0].shape[0]\n",
    "        lag_mode_ms = np.full((N,N), np.nan)\n",
    "        acc = [[[] for _ in range(N)] for __ in range(N)]\n",
    "        for A,L in items:\n",
    "            Lms = to_ms(L)\n",
    "            pres = (A==1)\n",
    "            for i in range(N):\n",
    "                for j in range(N):\n",
    "                    if i==j: continue\n",
    "                    if pres[i,j] and np.isfinite(Lms[i,j]) and Lms[i,j]!=0:\n",
    "                        acc[i][j].append(int(Lms[i,j]))\n",
    "        for i in range(N):\n",
    "            for j in range(N):\n",
    "                if i==j: continue\n",
    "                vals = acc[i][j]\n",
    "                if vals:\n",
    "                    lag_mode_ms[i,j] = Counter(vals).most_common(1)[0][0]\n",
    "        out[g] = lag_mode_ms\n",
    "    return out\n",
    "\n",
    "G_modal = modal_lag_per_edge(\"_gauss\")\n",
    "\n",
    "BINS = [50,100,150,200,250]\n",
    "\n",
    "def lag_counts_from_presence(P, L_mode_ms, thr):\n",
    "    \"\"\"\n",
    "    Given a group presence matrix P and modal lag matrix (ms), restrict to edges robust at 'thr',\n",
    "    then count edges per 50ms bin and summarize width, median, and IQR.\n",
    "    \"\"\"\n",
    "    N = P.shape[0]\n",
    "    diag = np.eye(N, dtype=bool)\n",
    "    R = (P >= thr) & (~diag)\n",
    "    vals = L_mode_ms[R]\n",
    "    vals = vals[np.isfinite(vals)].astype(int)\n",
    "    counts = {b: int((vals==b).sum()) for b in BINS}\n",
    "    width = sum(1 for b in BINS if counts[b]>0)\n",
    "    med = float(np.median(vals)) if vals.size else np.nan\n",
    "    q25,q75 = (np.percentile(vals,[25,75]) if vals.size else (np.nan,np.nan))\n",
    "    return counts, width, med, q25, q75\n",
    "\n",
    "def save_lag_summary(est_name, presence_dict, modal_dict, thr, tag):\n",
    "    \"\"\"\n",
    "    Saves a CSV with counts per lag bin, repertoire width (#occupied bins), median (ms), and IQR,\n",
    "    for robust edges at threshold 'thr'. Here used for Gaussian at 70% and 90%.\n",
    "    \"\"\"\n",
    "    rows = []\n",
    "    for g in [\"healthy\",\"PD-off\",\"PD-on\"]:\n",
    "        C,W,MED,q25,q75 = lag_counts_from_presence(presence_dict[g], modal_dict[g], thr)\n",
    "        rows.append({\n",
    "            \"estimator\": est_name,\n",
    "            \"group\": g,\n",
    "            \"threshold\": int(thr*100),\n",
    "            \"n_robust_edges\": sum(C.values()),\n",
    "            \"count_50\": C[50], \"count_100\": C[100], \"count_150\": C[150], \"count_200\": C[200], \"count_250\": C[250],\n",
    "            \"width_bins\": W,\n",
    "            \"median_ms\": MED,\n",
    "            \"iqr\": f\"[{int(q25)}–{int(q75)}]\" if np.isfinite(q25) else \"NA\"\n",
    "        })\n",
    "    df = pd.DataFrame(rows)\n",
    "    out = OUTCSV / f\"lag_repertoire_{est_name}_thr{int(thr*100)}.csv\"\n",
    "    df.to_csv(out, index=False)\n",
    "    print(df.to_string(index=False))\n",
    "    print(\"[csv]\", out)\n",
    "\n",
    "for thr in [0.70, 0.90]:\n",
    "    save_lag_summary(\"Gaussian\", G_presence, G_modal, thr, f\"thr{int(thr*100)}\")\n",
    "\n",
    "# ---------- Overlap (CONSENSUS) between estimators at same threshold; report Gaussian RECALL of KSG ----------\n",
    "def overlap_counts(thr):\n",
    "    \"\"\"\n",
    "    For each group, compute:\n",
    "      - consensus_edges: edges robust for BOTH KSG and Gaussian at 'thr'\n",
    "      - ksg_robust, gauss_robust: sizes of each robust set\n",
    "      - gauss_recall_of_ksg: consensus / #KSG-robust (recall of KSG by Gaussian)\n",
    "    Saves combined CSV elsewhere (precision is computed in Cell 5).\n",
    "    \"\"\"\n",
    "    rows = []\n",
    "    for g in [\"healthy\",\"PD-off\",\"PD-on\"]:\n",
    "        Pk = K_presence[g]\n",
    "        Pg = G_presence[g]\n",
    "        N = Pk.shape[0]\n",
    "        diag = np.eye(N, dtype=bool)\n",
    "        Rk = (Pk >= thr) & (~diag)\n",
    "        Rg = (Pg >= thr) & (~diag)\n",
    "        inter = (Rk & Rg).sum()\n",
    "        k_only = Rk.sum()\n",
    "        g_only = Rg.sum()\n",
    "        recall_g_of_k = inter / k_only if k_only>0 else np.nan\n",
    "        rows.append({\n",
    "            \"group\": g, \"threshold\": int(thr*100),\n",
    "            \"consensus_edges\": int(inter),\n",
    "            \"ksg_robust\": int(k_only),\n",
    "            \"gauss_robust\": int(g_only),\n",
    "            \"gauss_recall_of_ksg\": round(recall_g_of_k, 3)\n",
    "        })\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "df_ov_70 = overlap_counts(0.70)\n",
    "df_ov_90 = overlap_counts(0.90)\n",
    "df_ov   = pd.concat([df_ov_70, df_ov_90], ignore_index=True)\n",
    "df_ov.to_csv(OUTCSV / \"overlap_ksg_vs_gaussian.csv\", index=False)\n",
    "print(df_ov)\n",
    "\n",
    "# ---------- Optional placeholder for a side-by-side lag figure (not used in the paper here) ----------\n",
    "def plot_lag_hist_pair(thr=0.90, tag=\"thr90\"):\n",
    "    pass  # Keep intentionally empty; KSG timing figs are produced in the timing section.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e2e83fa-a2fe-4259-85eb-82d84383db98",
   "metadata": {},
   "source": [
    "# Gaussian lag histograms for robust edges (figures for LaTeX) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7ac06824-89cc-4371-9cff-47371d10d36f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: /home/majlepy2/myproject/Step-wise/figs/TE_lag/lag_histograms_gauss_thr70.png\n",
      "Saved: /home/majlepy2/myproject/Step-wise/figs/TE_lag/lag_histograms_gauss_thr90.png\n"
     ]
    }
   ],
   "source": [
    "# --- Gaussian lag histograms (tight, readable for LaTeX) ---\n",
    "# What this cell does:\n",
    "#   - Loads Gaussian per-session binaries and lag arrays\n",
    "#   - Computes per-edge modal lag (ms) per group, counting only sessions where the edge is present\n",
    "#   - Builds group presence matrices (fraction present)\n",
    "#   - Plots 3-panel histograms of modal lags for robust edges at a chosen threshold (70%, 90%)\n",
    "#   - Saves figures to OUT_FIGS\n",
    "#\n",
    "# Notes:\n",
    "#   - Lags coded as 1..5 are converted to milliseconds by ×50.\n",
    "#   - No across-edge FDR is applied here (matches the manuscript).\n",
    "#   - These figures support the \"Lag repertoires (Gaussian)\" subsection.\n",
    "\n",
    "from pathlib import Path\n",
    "import re, pickle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "\n",
    "BASE         = Path(\"/lustre/majlepy2/myproject\")\n",
    "RESULTS      = BASE / \"Results\"\n",
    "GAUSS_DIR    = RESULTS / \"gauss_results\"         # contains sub-*_gauss_binary.npy and *_gauss_max_te_lag.npy\n",
    "META_CSV     = BASE / \"subject_session_metadata.csv\"\n",
    "\n",
    "OUT_FIGS     = Path(\"/home/majlepy2/myproject/Step-wise/figs/TE_lag\")\n",
    "OUT_FIGS.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# --- metadata: map sub_ses -> group ---\n",
    "import pandas as pd\n",
    "meta = pd.read_csv(META_CSV)\n",
    "meta[\"sub_ses\"] = meta[\"subject\"] + \"_\" + meta[\"session\"]\n",
    "subses_to_group = dict(zip(meta[\"sub_ses\"], meta[\"group\"]))\n",
    "\n",
    "# --- helper to collect per-session binaries and lag arrays per group ---\n",
    "def collect_sessions_gaussian():\n",
    "    \"\"\"\n",
    "    Returns dict[group] -> list of (A_binary, L_max_te_lag) per session.\n",
    "    Diagonals are zeroed/NaN for A/L respectively.\n",
    "    \"\"\"\n",
    "    groups = {\"healthy\": [], \"PD-off\": [], \"PD-on\": []}\n",
    "    for bin_path in sorted(GAUSS_DIR.glob(\"sub-*_*_gauss_binary.npy\")):\n",
    "        stem = bin_path.name.replace(\"_gauss_binary.npy\",\"\")  # sub-XXX_ses-YY\n",
    "        parts = stem.split(\"_\")\n",
    "        sub_ses = \"_\".join(parts[:2])\n",
    "        g = subses_to_group.get(sub_ses)\n",
    "        if g not in groups:\n",
    "            continue\n",
    "        L = np.load(GAUSS_DIR / f\"{stem}_gauss_max_te_lag.npy\").astype(float)\n",
    "        A = np.load(bin_path).astype(np.uint8)\n",
    "        # clean diag\n",
    "        np.fill_diagonal(A, 0)\n",
    "        np.fill_diagonal(L, np.nan)\n",
    "        groups[g].append((A, L))\n",
    "    return groups\n",
    "\n",
    "G_sessions = collect_sessions_gaussian()\n",
    "assert all(len(G_sessions[g])>0 for g in G_sessions), \"Missing Gaussian sessions for some group.\"\n",
    "\n",
    "# --- compute modal lag per edge (ms), counting only when edge present ---\n",
    "def to_ms(L):\n",
    "    # If lags are coded as 1..5, convert to ms; otherwise leave as-is\n",
    "    Lc = L.copy()\n",
    "    finite = np.isfinite(Lc)\n",
    "    if finite.any() and np.nanmax(Lc[finite]) <= 10:\n",
    "        Lc[finite] = Lc[finite] * 50.0\n",
    "    return Lc\n",
    "\n",
    "def modal_lag_per_edge_gauss(G_sessions):\n",
    "    \"\"\"\n",
    "    For each group, aggregate session-wise lags for edges present (A==1) and take the mode (ms).\n",
    "    Returns dict[group] -> (N x N) matrix of modal lags (ms).\n",
    "    \"\"\"\n",
    "    out = {}\n",
    "    for g, items in G_sessions.items():\n",
    "        N = items[0][0].shape[0]\n",
    "        acc = [[[] for _ in range(N)] for __ in range(N)]\n",
    "        for A, L in items:\n",
    "            Lms = to_ms(L)\n",
    "            present = (A == 1)\n",
    "            for i in range(N):\n",
    "                for j in range(N):\n",
    "                    if i == j: \n",
    "                        continue\n",
    "                    if present[i, j] and np.isfinite(Lms[i, j]) and Lms[i, j] != 0:\n",
    "                        acc[i][j].append(int(Lms[i, j]))\n",
    "        mode = np.full((N, N), np.nan)\n",
    "        for i in range(N):\n",
    "            for j in range(N):\n",
    "                if i == j: \n",
    "                    continue\n",
    "                if acc[i][j]:\n",
    "                    mode[i][j] = Counter(acc[i][j]).most_common(1)[0][0]\n",
    "        out[g] = mode\n",
    "    return out\n",
    "\n",
    "G_modal = modal_lag_per_edge_gauss(G_sessions)\n",
    "\n",
    "# --- group-level presence matrices (fraction present) ---\n",
    "def group_presence_gauss(G_sessions):\n",
    "    pres = {}\n",
    "    for g, items in G_sessions.items():\n",
    "        A_stack = np.stack([A for A, _ in items], axis=0)  # S x N x N\n",
    "        P = A_stack.mean(axis=0)\n",
    "        np.fill_diagonal(P, 0.0)\n",
    "        pres[g] = P\n",
    "    return pres\n",
    "\n",
    "G_presence = group_presence_gauss(G_sessions)\n",
    "\n",
    "# --- plot helper: one row (Healthy / PD-off / PD-on) per threshold ---\n",
    "BINS = [50, 100, 150, 200, 250]\n",
    "\n",
    "def plot_gauss_lag_hist(thr=0.70, outname=\"lag_histograms_gauss_thr70.png\"):\n",
    "    \"\"\"\n",
    "    Plot 3-panel histograms of modal lag bins for robust edges (presence ≥ thr), one panel per group.\n",
    "    Saves to OUT_FIGS/outname.\n",
    "    \"\"\"\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(8.4, 2.8), dpi=200)  # tight & readable in LaTeX\n",
    "    groups = [\"healthy\", \"PD-off\", \"PD-on\"]\n",
    "    maxy = 0\n",
    "    # precompute counts for harmonized y-limits\n",
    "    counts_by_g = {}\n",
    "    for g in groups:\n",
    "        P = G_presence[g]; Lm = G_modal[g]\n",
    "        N = P.shape[0]\n",
    "        R = (P >= thr) & (~np.eye(N, dtype=bool))\n",
    "        vals = Lm[R]\n",
    "        vals = vals[np.isfinite(vals)].astype(int)\n",
    "        C = [int((vals == b).sum()) for b in BINS]\n",
    "        counts_by_g[g] = C\n",
    "        maxy = max(maxy, max(C) if C else 0)\n",
    "\n",
    "    for ax, g in zip(axes, groups):\n",
    "        C = counts_by_g[g]\n",
    "        ax.bar(range(len(BINS)), C, width=0.6)\n",
    "        # annotate counts\n",
    "        for xi, c in enumerate(C):\n",
    "            if c > 0:\n",
    "                ax.text(xi, c + max(1, 0.03*maxy), str(c), ha=\"center\", va=\"bottom\", fontsize=8)\n",
    "        ax.set_xticks(range(len(BINS)))\n",
    "        ax.set_xticklabels([f\"{b}\" for b in BINS], fontsize=9)\n",
    "        ax.set_ylim(0, max(1, maxy*1.2))\n",
    "        ax.set_title(g, fontsize=10)\n",
    "        ax.grid(axis=\"y\", alpha=0.3, linewidth=0.5)\n",
    "    fig.suptitle(f\"Gaussian modal delays (robust edges, ≥ {int(thr*100)}% of sessions)\", fontsize=11)\n",
    "    fig.text(0.5, 0.01, \"Delay bin (ms)\", ha=\"center\", fontsize=10)\n",
    "    fig.text(0.01, 0.5, \"Count of robust edges\", va=\"center\", rotation=\"vertical\", fontsize=10)\n",
    "    fig.tight_layout(rect=[0.02, 0.04, 1, 0.92])\n",
    "    fig.savefig(OUT_FIGS / outname, bbox_inches=\"tight\")\n",
    "    plt.close(fig)\n",
    "    print(\"Saved:\", OUT_FIGS / outname)\n",
    "\n",
    "# Figures used for the \"Lag repertoires (Gaussian)\" subsection:\n",
    "plot_gauss_lag_hist(0.70, \"lag_histograms_gauss_thr70.png\")\n",
    "plot_gauss_lag_hist(0.90, \"lag_histograms_gauss_thr90.png\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52ea6b23-3149-4e17-8291-a91a3a2f4880",
   "metadata": {},
   "source": [
    "# List overlapping edges (consensus) at 70%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b21a77c4-1fc8-4233-94a4-5e0ab62ab836",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Group: healthy - Robust edges present in BOTH KSG and Gaussian (threshold 70%):\n",
      "  Edge: 1 -> 20\n",
      "  Edge: 2 -> 12\n",
      "  Edge: 5 -> 3\n",
      "  Edge: 7 -> 6\n",
      "  Edge: 21 -> 0\n",
      "\n",
      "Group: PD-off - Robust edges present in BOTH KSG and Gaussian (threshold 70%):\n",
      "  Edge: 0 -> 11\n",
      "  Edge: 1 -> 3\n",
      "  Edge: 8 -> 6\n",
      "  Edge: 9 -> 18\n",
      "  Edge: 14 -> 17\n",
      "  Edge: 17 -> 21\n",
      "  Edge: 19 -> 18\n",
      "  Edge: 21 -> 0\n",
      "  Edge: 21 -> 17\n",
      "\n",
      "Group: PD-on - Robust edges present in BOTH KSG and Gaussian (threshold 70%):\n",
      "  Edge: 0 -> 21\n",
      "  Edge: 4 -> 18\n",
      "  Edge: 5 -> 0\n",
      "  Edge: 6 -> 5\n",
      "  Edge: 8 -> 12\n",
      "  Edge: 9 -> 19\n",
      "  Edge: 14 -> 17\n",
      "  Edge: 17 -> 14\n",
      "  Edge: 18 -> 1\n",
      "  Edge: 18 -> 21\n",
      "  Edge: 21 -> 0\n"
     ]
    }
   ],
   "source": [
    "# Report consensus edges (KSG ∩ Gaussian) at 70% presence, by group.\n",
    "# This is a diagnostic printout to inspect which specific directed edges overlap.\n",
    "# For summary counts and recall/precision tables, see Cells 1 and 5.\n",
    "\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "ksg_dir = Path('/lustre/majlepy2/myproject/Results/ksg_results')\n",
    "gauss_dir = Path('/lustre/majlepy2/myproject/Results/gauss_results')\n",
    "groups = ['healthy', 'PD-off', 'PD-on']\n",
    "thresh = 0.7\n",
    "\n",
    "for group in groups:\n",
    "    edge_presence_ksg = np.load(ksg_dir / f\"{group}_ksg_edge_presence.npy\")\n",
    "    edge_presence_gauss = np.load(gauss_dir / f\"{group}_gauss_edge_presence.npy\")\n",
    "    \n",
    "    robust_ksg = edge_presence_ksg >= thresh\n",
    "    robust_gauss = edge_presence_gauss >= thresh\n",
    "    \n",
    "    overlap_mask = np.logical_and(robust_ksg, robust_gauss)\n",
    "    \n",
    "    sources, targets = np.where(overlap_mask)\n",
    "    print(f\"\\nGroup: {group} - Robust edges present in BOTH KSG and Gaussian (threshold {int(thresh*100)}%):\")\n",
    "    if len(sources) == 0:\n",
    "        print(\"  No overlapping edges found.\")\n",
    "    else:\n",
    "        for src, tgt in zip(sources, targets):\n",
    "            print(f\"  Edge: {src} -> {tgt}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80aa7ddd-2130-4fbc-8d99-48d574f558df",
   "metadata": {},
   "source": [
    "# List overlapping edges (consensus) at 90%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7e78d7b3-af56-4d6f-a945-2eff1f4fdcc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Group: healthy - Robust edges present in BOTH KSG and Gaussian (threshold 90%):\n",
      "  No overlapping edges found.\n",
      "\n",
      "Group: PD-off - Robust edges present in BOTH KSG and Gaussian (threshold 90%):\n",
      "  Edge: 14 -> 17\n",
      "\n",
      "Group: PD-on - Robust edges present in BOTH KSG and Gaussian (threshold 90%):\n",
      "  Edge: 0 -> 21\n",
      "  Edge: 21 -> 0\n"
     ]
    }
   ],
   "source": [
    "# Same as Cell 3 but at 90% presence. Useful for manual inspection of consensus edges at stricter robustness.\n",
    "\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "ksg_dir = Path('/lustre/majlepy2/myproject/Results/ksg_results')\n",
    "gauss_dir = Path('/lustre/majlepy2/myproject/Results/gauss_results')\n",
    "groups = ['healthy', 'PD-off', 'PD-on']\n",
    "thresh = 0.9\n",
    "\n",
    "for group in groups:\n",
    "    edge_presence_ksg = np.load(ksg_dir / f\"{group}_ksg_edge_presence.npy\")\n",
    "    edge_presence_gauss = np.load(gauss_dir / f\"{group}_gauss_edge_presence.npy\")\n",
    "    \n",
    "    robust_ksg = edge_presence_ksg >= thresh\n",
    "    robust_gauss = edge_presence_gauss >= thresh\n",
    "    \n",
    "    overlap_mask = np.logical_and(robust_ksg, robust_gauss)\n",
    "    \n",
    "    sources, targets = np.where(overlap_mask)\n",
    "    print(f\"\\nGroup: {group} - Robust edges present in BOTH KSG and Gaussian (threshold {int(thresh*100)}%):\")\n",
    "    if len(sources) == 0:\n",
    "        print(\"  No overlapping edges found.\")\n",
    "    else:\n",
    "        for src, tgt in zip(sources, targets):\n",
    "            print(f\"  Edge: {src} -> {tgt}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "016959be-b59a-4592-96c7-c7bc931b917d",
   "metadata": {},
   "source": [
    "# Estimator overlap table with Gaussian precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7d6f5d37-b8ca-4d82-8672-9dbc59d14620",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  group  threshold  consensus_edges  ksg_robust  gauss_robust  gauss_precision_wrt_ksg\n",
      "healthy         70                5         331             6                    0.833\n",
      " PD-off         70                9         296             9                    1.000\n",
      "  PD-on         70               11         331            12                    0.917\n",
      "healthy         90                0         117             1                    0.000\n",
      " PD-off         90                1          84             1                    1.000\n",
      "  PD-on         90                2         140             2                    1.000\n",
      "[csv] /home/majlepy2/myproject/Step-wise/Comparison/precision_gaussian_wrt_ksg.csv\n"
     ]
    }
   ],
   "source": [
    "# Build a CSV summary of estimator overlap including Gaussian precision w.r.t. KSG.\n",
    "# Definitions (match manuscript):\n",
    "#   consensus_edges = |KSG_robust ∩ Gaussian_robust|\n",
    "#   gauss_precision_wrt_ksg = consensus_edges / |Gaussian_robust|\n",
    "# Recall (consensus / |KSG_robust|) is produced in Cell 1.\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# ---- paths ----\n",
    "KSG_DIR   = Path('/lustre/majlepy2/myproject/Results/ksg_results')\n",
    "GAUSS_DIR = Path('/lustre/majlepy2/myproject/Results/gauss_results')\n",
    "OUTCSV    = Path('/home/majlepy2/myproject/Step-wise/Comparison')\n",
    "OUTCSV.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "GROUPS = ['healthy', 'PD-off', 'PD-on']\n",
    "THRS   = [0.70, 0.90]  # add 0.50 if you want\n",
    "\n",
    "def robust_mask(P, thr):\n",
    "    N = P.shape[0]\n",
    "    diag = np.eye(N, dtype=bool)\n",
    "    return (P >= thr) & (~diag)\n",
    "\n",
    "rows = []\n",
    "for thr in THRS:\n",
    "    for g in GROUPS:\n",
    "        # load presence matrices\n",
    "        Pk = np.load(KSG_DIR   / f\"{g}_ksg_edge_presence.npy\")\n",
    "        Pg = np.load(GAUSS_DIR / f\"{g}_gauss_edge_presence.npy\")\n",
    "        # robust sets\n",
    "        Rk = robust_mask(Pk, thr)\n",
    "        Rg = robust_mask(Pg, thr)\n",
    "        # consensus\n",
    "        inter = (Rk & Rg).sum()\n",
    "        k_only = Rk.sum()\n",
    "        g_only = Rg.sum()\n",
    "        # precision: fraction of Gaussian-robust edges also present in KSG\n",
    "        precision = inter / g_only if g_only > 0 else 0.0\n",
    "\n",
    "        rows.append({\n",
    "            \"group\": g,\n",
    "            \"threshold\": int(thr*100),\n",
    "            \"consensus_edges\": int(inter),\n",
    "            \"ksg_robust\": int(k_only),\n",
    "            \"gauss_robust\": int(g_only),\n",
    "            \"gauss_precision_wrt_ksg\": round(precision, 3),\n",
    "        })\n",
    "\n",
    "df_precision = pd.DataFrame(rows)\n",
    "out_file = OUTCSV / \"precision_gaussian_wrt_ksg.csv\"\n",
    "df_precision.to_csv(out_file, index=False)\n",
    "print(df_precision.to_string(index=False))\n",
    "print(\"[csv]\", out_file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61fafa5a-f3f8-43ba-a97b-1a87f54a72a7",
   "metadata": {},
   "source": [
    "# Consensus-edge lag distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5025b84a-10b5-40d9-a464-caf2581d22c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  group  threshold  consensus_total  count_50  count_100  count_150  count_200  count_250  prop_50ms  median_ms  width_bins\n",
      "healthy         70                5         5          0          0          0          0      1.000       50.0           1\n",
      " PD-off         70                9         7          2          0          0          0      0.778       50.0           2\n",
      "  PD-on         70               11        10          0          0          1          0      0.909       50.0           2\n",
      "[csv] /home/majlepy2/myproject/Step-wise/Comparison/consensus_lag_distribution_thr70.csv\n",
      "  group  threshold  consensus_total  count_50  count_100  count_150  count_200  count_250 prop_50ms  median_ms  width_bins\n",
      "healthy         90                0         0          0          0          0          0        NA        NaN           0\n",
      " PD-off         90                1         1          0          0          0          0       1.0       50.0           1\n",
      "  PD-on         90                2         2          0          0          0          0       1.0       50.0           1\n",
      "[csv] /home/majlepy2/myproject/Step-wise/Comparison/consensus_lag_distribution_thr90.csv\n"
     ]
    }
   ],
   "source": [
    "# ============================\n",
    "# Consensus lag distribution (KSG ∩ Gaussian) at 70% and 90%\n",
    "# Outputs:\n",
    "#   - CSVs with counts per lag bin (50..250 ms) for the consensus set, per group and threshold\n",
    "#   - Console summary with proportions at 50 ms\n",
    "#\n",
    "# Requirements:\n",
    "#   - KSG group presence matrices exist in: Results/ksg_results/*_ksg_edge_presence.npy\n",
    "#   - Gaussian per-session arrays exist in: Results/gauss_results/sub-*_*_gauss_binary.npy and *_gauss_max_te_lag.npy\n",
    "#   - subject_session_metadata.csv maps sessions to groups\n",
    "#\n",
    "# Notes:\n",
    "#   - No across-edge FDR; diagonals excluded\n",
    "#   - Lag bins coded 1..5 are converted to ms by ×50\n",
    "# ============================\n",
    "\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "\n",
    "# ---- paths ----\n",
    "BASE       = Path('/lustre/majlepy2/myproject')\n",
    "RESULTS    = BASE / 'Results'\n",
    "KSG_DIR    = RESULTS / 'ksg_results'\n",
    "GAUSS_DIR  = RESULTS / 'gauss_results'\n",
    "META_CSV   = BASE / 'subject_session_metadata.csv'\n",
    "\n",
    "OUTBASE    = Path('/home/majlepy2/myproject/Step-wise')\n",
    "OUTCSV     = OUTBASE / 'Comparison'\n",
    "OUTCSV.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# ---- groups / thresholds ----\n",
    "GROUPS = ['healthy', 'PD-off', 'PD-on']\n",
    "THRS   = [0.70, 0.90]\n",
    "BINS   = [50, 100, 150, 200, 250]\n",
    "\n",
    "# ---- read metadata to map sub_ses -> group ----\n",
    "meta = pd.read_csv(META_CSV)\n",
    "meta['sub_ses'] = meta['subject'] + '_' + meta['session']\n",
    "subses_to_group = dict(zip(meta['sub_ses'], meta['group']))\n",
    "\n",
    "# ---- helper: convert lag bins to ms if needed ----\n",
    "def to_ms(arr):\n",
    "    a = arr.copy()\n",
    "    finite = np.isfinite(a)\n",
    "    if finite.any() and np.nanmax(a[finite]) <= 10:\n",
    "        a[finite] = a[finite] * 50.0\n",
    "    return a\n",
    "\n",
    "# ---- build Gaussian per-group modal lag matrices from per-session arrays ----\n",
    "def gaussian_modal_lag_by_group():\n",
    "    \"\"\"\n",
    "    Returns dict[group] -> (N x N) array of modal lag (ms), counting only sessions with edge present.\n",
    "    \"\"\"\n",
    "    sessions = {'healthy': [], 'PD-off': [], 'PD-on': []}\n",
    "    # collect per-session arrays\n",
    "    for bin_path in sorted(GAUSS_DIR.glob('sub-*_*_gauss_binary.npy')):\n",
    "        stem = bin_path.name.replace('_gauss_binary.npy', '')\n",
    "        parts = stem.split('_')\n",
    "        sub_ses = '_'.join(parts[:2])\n",
    "        g = subses_to_group.get(sub_ses)\n",
    "        if g not in sessions:\n",
    "            continue\n",
    "        A = np.load(bin_path).astype(np.uint8)\n",
    "        L = np.load(GAUSS_DIR / f'{stem}_gauss_max_te_lag.npy').astype(float)\n",
    "        np.fill_diagonal(A, 0)\n",
    "        np.fill_diagonal(L, np.nan)\n",
    "        sessions[g].append((A, L))\n",
    "\n",
    "    # compute modal lags\n",
    "    out = {}\n",
    "    for g, items in sessions.items():\n",
    "        if not items:\n",
    "            raise RuntimeError(f'No Gaussian sessions found for group {g}')\n",
    "        N = items[0][0].shape[0]\n",
    "        # accumulator of observed lags per directed edge\n",
    "        acc = [[[] for _ in range(N)] for __ in range(N)]\n",
    "        for A, L in items:\n",
    "            Lms = to_ms(L)\n",
    "            present = (A == 1)\n",
    "            for i in range(N):\n",
    "                for j in range(N):\n",
    "                    if i == j: \n",
    "                        continue\n",
    "                    if present[i, j] and np.isfinite(Lms[i, j]) and Lms[i, j] != 0:\n",
    "                        acc[i][j].append(int(Lms[i, j]))\n",
    "        mode = np.full((N, N), np.nan)\n",
    "        for i in range(N):\n",
    "            for j in range(N):\n",
    "                if i == j:\n",
    "                    continue\n",
    "                if acc[i][j]:\n",
    "                    mode[i, j] = Counter(acc[i][j]).most_common(1)[0][0]\n",
    "        out[g] = mode\n",
    "    return out\n",
    "\n",
    "# ---- load group presence (KSG and Gaussian) ----\n",
    "K_presence = {\n",
    "    g: np.load(KSG_DIR / f'{g}_ksg_edge_presence.npy')\n",
    "    for g in GROUPS\n",
    "}\n",
    "G_presence = {\n",
    "    g: np.load(GAUSS_DIR / f'{g}_gauss_edge_presence.npy')\n",
    "    for g in GROUPS\n",
    "}\n",
    "\n",
    "# ---- compute Gaussian modal lags per group ----\n",
    "G_modal = gaussian_modal_lag_by_group()\n",
    "\n",
    "# ---- for each threshold, intersect consensus mask with Gaussian modal lags and summarize ----\n",
    "def consensus_lag_summary(thr):\n",
    "    rows = []\n",
    "    for g in GROUPS:\n",
    "        Pk = K_presence[g]\n",
    "        Pg = G_presence[g]\n",
    "        N  = Pk.shape[0]\n",
    "        diag = np.eye(N, dtype=bool)\n",
    "\n",
    "        Rk = (Pk >= thr) & (~diag)     # robust in KSG\n",
    "        Rg = (Pg >= thr) & (~diag)     # robust in Gaussian\n",
    "        cons = Rk & Rg                 # consensus mask\n",
    "\n",
    "        Lm = G_modal[g]\n",
    "        vals = Lm[cons]\n",
    "        vals = vals[np.isfinite(vals)].astype(int)\n",
    "\n",
    "        counts = {b: int((vals == b).sum()) for b in BINS}\n",
    "        total  = int(vals.size)\n",
    "        frac50 = (counts[50] / total) if total > 0 else np.nan\n",
    "        width  = sum(1 for b in BINS if counts[b] > 0)\n",
    "        med    = float(np.median(vals)) if total > 0 else np.nan\n",
    "\n",
    "        rows.append({\n",
    "            'group': g,\n",
    "            'threshold': int(thr * 100),\n",
    "            'consensus_total': total,\n",
    "            'count_50': counts[50],\n",
    "            'count_100': counts[100],\n",
    "            'count_150': counts[150],\n",
    "            'count_200': counts[200],\n",
    "            'count_250': counts[250],\n",
    "            'prop_50ms': round(frac50, 3) if np.isfinite(frac50) else 'NA',\n",
    "            'median_ms': med,\n",
    "            'width_bins': width\n",
    "        })\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "# ---- run and save CSVs for 70% and 90% ----\n",
    "all_df = []\n",
    "for thr in THRS:\n",
    "    df = consensus_lag_summary(thr)\n",
    "    all_df.append(df)\n",
    "    out = OUTCSV / f'consensus_lag_distribution_thr{int(thr*100)}.csv'\n",
    "    df.to_csv(out, index=False)\n",
    "    print(df.to_string(index=False))\n",
    "    print('[csv]', out)\n",
    "\n",
    "consensus_lag_df = pd.concat(all_df, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93651db1-df50-448f-9307-7e852e5efb5d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
