{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6bc53d35-6a0c-4a96-8b98-047aca6d0116",
   "metadata": {},
   "source": [
    "# Temporal lag structure (Gaussian) — **50%, 70%, 90%** _(complementary)_\n",
    "\n",
    "**Goal.** Mirror the KSG lag analysis for the **Gaussian** estimator: summarise the **modal TE lag** (50–250 ms in 50 ms steps) for **robust edges** within each group.\n",
    "\n",
    "**Inputs**\n",
    "- `Results/gauss_results/sub-XXX_ses-YYY_combined_gauss_binary.npy`\n",
    "- `Results/gauss_results/sub-XXX_ses-YYY_combined_gauss_max_te_lag.npy`\n",
    "- `subject_session_metadata.csv`\n",
    "\n",
    "**Method**\n",
    "1. For each group and each edge, collect **per-session `max_te_lag`** values **only when the edge is significant** in that session (`binary == 1`).\n",
    "2. Compute the **modal lag (ms)** per edge **across sessions** in that group (ties resolved deterministically by first occurrence).\n",
    "3. Using **group presence** (fraction of sessions with the edge), define **robust sets** at **50%**, **70%**, and **90%**.\n",
    "4. Within each robust set, summarise the **lag repertoire**:\n",
    "   - counts per bin (50, 100, 150, 200, 250 ms),\n",
    "   - repertoire width (number of occupied bins),\n",
    "   - median bin and IQR (in ms).\n",
    "5. Plot group histograms for **50%**, **70%**, and **90%** (saved as PNGs).\n",
    "\n",
    "**Key choices**\n",
    "- **No across-edge FDR** at extraction (`fdr=False`), diagonal excluded.\n",
    "- EEG downsampled to **20 Hz** → 5 lag bins (50–250 ms).\n",
    "- This Gaussian section is **complementary/appendix**; your Results narrative emphasises KSG.\n",
    "\n",
    "**Outputs (for Appendix)**\n",
    "- CSVs: `gauss_lag_repertoire_thr50.csv`, `gauss_lag_repertoire_thr70.csv`, `gauss_lag_repertoire_thr90.csv`\n",
    "- Figures: `lag_histograms_gauss_thr50.png`, `lag_histograms_gauss_thr70.png`, `lag_histograms_gauss_thr90.png`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "876b2cf4-1bf5-4b32-b220-08c4b3575ed9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "healthy: 12 sessions\n",
      "PD-off: 12 sessions\n",
      "PD-on: 12 sessions\n",
      "Saved: /home/majlepy2/myproject/Step-wise/gauss_lag_repertoire_thr50.csv\n",
      "  group  n_robust_edges  count_50  count_100  count_150  count_200  count_250  repertoire_width_bins  median_lag_ms iqr_lag_ms\n",
      "Healthy              81        70         10          1          0          0                      3           50.0    [50–50]\n",
      " PD-off             105        90         13          1          1          0                      4           50.0    [50–50]\n",
      "  PD-on             110        93         10          1          3          3                      5           50.0    [50–50]\n",
      "Saved: /home/majlepy2/myproject/Step-wise/figs/lag_histograms_gauss_thr50.png\n",
      "Saved: /home/majlepy2/myproject/Step-wise/gauss_lag_repertoire_thr70.csv\n",
      "  group  n_robust_edges  count_50  count_100  count_150  count_200  count_250  repertoire_width_bins  median_lag_ms iqr_lag_ms\n",
      "Healthy               6         6          0          0          0          0                      1           50.0    [50–50]\n",
      " PD-off               9         7          2          0          0          0                      2           50.0    [50–50]\n",
      "  PD-on              12        11          0          0          1          0                      2           50.0    [50–50]\n",
      "Saved: /home/majlepy2/myproject/Step-wise/figs/lag_histograms_gauss_thr70.png\n",
      "Saved: /home/majlepy2/myproject/Step-wise/gauss_lag_repertoire_thr90.csv\n",
      "  group  n_robust_edges  count_50  count_100  count_150  count_200  count_250  repertoire_width_bins  median_lag_ms iqr_lag_ms\n",
      "Healthy               1         1          0          0          0          0                      1           50.0    [50–50]\n",
      " PD-off               1         1          0          0          0          0                      1           50.0    [50–50]\n",
      "  PD-on               2         2          0          0          0          0                      1           50.0    [50–50]\n",
      "Saved: /home/majlepy2/myproject/Step-wise/figs/lag_histograms_gauss_thr90.png\n"
     ]
    }
   ],
   "source": [
    "# ============================\n",
    "# STEP 3 (Gaussian): Temporal lag structure (max_te_lag)\n",
    "# Mirrors the KSG Step 3, now for the Gaussian estimator.\n",
    "# Outputs 50%, 70% and 90% summaries + plots (complementary/appendix).\n",
    "# ============================\n",
    "from pathlib import Path\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "\n",
    "# -------- Paths --------\n",
    "BASE      = Path(\"/lustre/majlepy2/myproject\")\n",
    "RESULTS   = BASE / \"Results\" / \"gauss_results\"\n",
    "META_CSV  = BASE / \"subject_session_metadata.csv\"\n",
    "\n",
    "OUTROOT   = Path(\"/home/majlepy2/myproject/Step-wise\")\n",
    "FIGDIR    = OUTROOT / \"figs\"\n",
    "FIGDIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# -------- Metadata: session -> group --------\n",
    "meta = pd.read_csv(META_CSV)\n",
    "meta[\"sub_ses\"] = meta[\"subject\"] + \"_\" + meta[\"session\"]\n",
    "subses_to_group = dict(zip(meta[\"sub_ses\"], meta[\"group\"]))\n",
    "\n",
    "# -------- Load group presence (reused if saved); else compute quickly --------\n",
    "def load_or_compute_presence():\n",
    "    pres = {}\n",
    "    for g in [\"healthy\", \"PD-off\", \"PD-on\"]:\n",
    "        f = RESULTS / f\"{g}_gauss_edge_presence.npy\"\n",
    "        if f.exists():\n",
    "            pres[g] = np.load(f)\n",
    "        else:\n",
    "            # compute presence by averaging binaries in this group\n",
    "            mats = []\n",
    "            for npy in sorted(RESULTS.glob(\"sub-*_*_combined_gauss_binary.npy\")):\n",
    "                stem = npy.name.replace(\"_binary.npy\", \"\")\n",
    "                m = re.match(r\"(sub-\\d+)_([^_]*)_combined_gauss\", stem)\n",
    "                if not m:\n",
    "                    continue\n",
    "                sub_ses = f\"{m.group(1)}_{m.group(2)}\"\n",
    "                if subses_to_group.get(sub_ses) != g:\n",
    "                    continue\n",
    "                A = np.load(npy).astype(np.uint8)\n",
    "                mats.append(A)\n",
    "            if not mats:\n",
    "                raise RuntimeError(f\"No binaries found for group '{g}' to compute presence.\")\n",
    "            M = np.stack(mats, axis=0)\n",
    "            P = M.mean(axis=0)\n",
    "            np.fill_diagonal(P, 0.0)\n",
    "            pres[g] = P\n",
    "            np.save(f, P)\n",
    "            print(f\"[INFO] Presence computed and saved for {g}: shape={P.shape}\")\n",
    "    return pres\n",
    "\n",
    "presence = load_or_compute_presence()\n",
    "P_H, P_OFF, P_ON = presence[\"healthy\"], presence[\"PD-off\"], presence[\"PD-on\"]\n",
    "N = P_H.shape[0]\n",
    "diag = np.eye(N, dtype=bool)\n",
    "\n",
    "def robust_mask(P, thr):\n",
    "    return (P >= thr) & (~diag)\n",
    "\n",
    "# -------- Collect per-session binaries and max_te_lag arrays --------\n",
    "def load_group_sessions():\n",
    "    groups = {\"healthy\": [], \"PD-off\": [], \"PD-on\": []}\n",
    "    for bin_path in sorted(RESULTS.glob(\"sub-*_*_combined_gauss_binary.npy\")):\n",
    "        stem = bin_path.name.replace(\"_binary.npy\", \"\")  # sub-XXX_ses-YY_combined_gauss\n",
    "        m = re.match(r\"(sub-\\d+)_([^_]*)_combined_gauss\", stem)\n",
    "        if not m:\n",
    "            continue\n",
    "        sub, ses = m.group(1), m.group(2)\n",
    "        sub_ses = f\"{sub}_{ses}\"\n",
    "        g = subses_to_group.get(sub_ses)\n",
    "        if g not in groups:\n",
    "            continue\n",
    "        lag_path = RESULTS / f\"{stem}_max_te_lag.npy\"\n",
    "        if not lag_path.exists():\n",
    "            raise FileNotFoundError(f\"Missing max_te_lag for {stem}\")\n",
    "        A = np.load(bin_path).astype(np.uint8)\n",
    "        L = np.load(lag_path).astype(float)\n",
    "        groups[g].append((A, L))\n",
    "    for g, lst in groups.items():\n",
    "        print(f\"{g}: {len(lst)} sessions\")\n",
    "    return groups\n",
    "\n",
    "group_sessions = load_group_sessions()\n",
    "\n",
    "# -------- Utility: convert lag coding to ms (1..5 -> 50..250, else pass-through) --------\n",
    "def to_ms(arr):\n",
    "    a = arr.copy()\n",
    "    finite = np.isfinite(a)\n",
    "    if np.nanmax(a[finite]) <= 10:  # looks like bin indices\n",
    "        a[finite] = a[finite] * 50.0\n",
    "    return a\n",
    "\n",
    "# -------- Per-group modal lag per edge, masked by significance in that session --------\n",
    "def modal_lag_per_edge(session_list):\n",
    "    \"\"\"\n",
    "    session_list: list of (A, L) where A is binary (N,N) and L is lag array (N,N)\n",
    "    Returns: (N,N) array of modal lag in ms, np.nan where absent.\n",
    "    \"\"\"\n",
    "    if not session_list:\n",
    "        raise RuntimeError(\"Empty session list.\")\n",
    "    N = session_list[0][0].shape[0]\n",
    "    lag_mode_ms = np.full((N, N), np.nan, dtype=float)\n",
    "\n",
    "    # accumulate lags per edge\n",
    "    acc = [[[] for _ in range(N)] for __ in range(N)]\n",
    "    for A, L in session_list:\n",
    "        L_ms = to_ms(L)\n",
    "        present = (A == 1)\n",
    "        for i in range(N):\n",
    "            for j in range(N):\n",
    "                if i == j:\n",
    "                    continue\n",
    "                if present[i, j] and np.isfinite(L_ms[i, j]) and L_ms[i, j] != 0:\n",
    "                    acc[i][j].append(int(L_ms[i, j]))\n",
    "\n",
    "    # modal lag (ties: Counter.most_common first-encounter rule; deterministic with fixed order)\n",
    "    for i in range(N):\n",
    "        for j in range(N):\n",
    "            if i == j:\n",
    "                continue\n",
    "            vals = acc[i][j]\n",
    "            if vals:\n",
    "                lag_mode_ms[i, j] = Counter(vals).most_common(1)[0][0]\n",
    "    return lag_mode_ms\n",
    "\n",
    "L_mode_H_ms   = modal_lag_per_edge(group_sessions[\"healthy\"])\n",
    "L_mode_OFF_ms = modal_lag_per_edge(group_sessions[\"PD-off\"])\n",
    "L_mode_ON_ms  = modal_lag_per_edge(group_sessions[\"PD-on\"])\n",
    "\n",
    "# -------- Summaries for 50%, 70%, 90% --------\n",
    "BINS_MS = np.array([50, 100, 150, 200, 250], dtype=int)\n",
    "\n",
    "def robust_modal_values(P, L_mode_ms, thr):\n",
    "    R = robust_mask(P, thr)\n",
    "    vals = L_mode_ms[R]\n",
    "    vals = vals[np.isfinite(vals)]\n",
    "    return vals.astype(int)\n",
    "\n",
    "def counts_width_median_iqr(vals):\n",
    "    counts = {int(b): int((vals == b).sum()) for b in BINS_MS}\n",
    "    width = sum(1 for b in BINS_MS if counts[b] > 0)\n",
    "    if vals.size:\n",
    "        med = float(np.median(vals))\n",
    "        q25, q75 = np.percentile(vals, [25, 75])\n",
    "        iqr_str = f\"[{int(q25)}–{int(q75)}]\"\n",
    "    else:\n",
    "        med, iqr_str = np.nan, \"NA\"\n",
    "    return counts, width, med, iqr_str\n",
    "\n",
    "def summarize_and_plot(thr, tag):\n",
    "    vals_H   = robust_modal_values(P_H,   L_mode_H_ms,   thr)\n",
    "    vals_OFF = robust_modal_values(P_OFF, L_mode_OFF_ms, thr)\n",
    "    vals_ON  = robust_modal_values(P_ON,  L_mode_ON_ms,  thr)\n",
    "\n",
    "    C_H,   W_H,   MED_H,   IQR_H   = counts_width_median_iqr(vals_H)\n",
    "    C_OFF, W_OFF, MED_OFF, IQR_OFF = counts_width_median_iqr(vals_OFF)\n",
    "    C_ON,  W_ON,  MED_ON,  IQR_ON  = counts_width_median_iqr(vals_ON)\n",
    "\n",
    "    # CSV summary\n",
    "    rows = []\n",
    "    def row(name, counts, width, med, iqr):\n",
    "        return {\n",
    "            \"group\": name,\n",
    "            \"n_robust_edges\": int(sum(counts.values())),\n",
    "            \"count_50\": counts[50], \"count_100\": counts[100],\n",
    "            \"count_150\": counts[150], \"count_200\": counts[200], \"count_250\": counts[250],\n",
    "            \"repertoire_width_bins\": width,\n",
    "            \"median_lag_ms\": med,\n",
    "            \"iqr_lag_ms\": iqr\n",
    "        }\n",
    "    rows.append(row(\"Healthy\", C_H, W_H, MED_H, IQR_H))\n",
    "    rows.append(row(\"PD-off\",  C_OFF, W_OFF, MED_OFF, IQR_OFF))\n",
    "    rows.append(row(\"PD-on\",   C_ON, W_ON, MED_ON, IQR_ON))\n",
    "    df = pd.DataFrame(rows)\n",
    "    csv_out = OUTROOT / f\"gauss_lag_repertoire_thr{int(thr*100)}.csv\"\n",
    "    df.to_csv(csv_out, index=False)\n",
    "    print(\"Saved:\", csv_out)\n",
    "    print(df.to_string(index=False))\n",
    "\n",
    "    # Figure\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(11, 3.5), dpi=200, sharey=True)\n",
    "    for ax, counts, title in zip(\n",
    "        axes,\n",
    "        [C_H, C_OFF, C_ON],\n",
    "        [\"Healthy\", \"PD-off\", \"PD-on\"]\n",
    "    ):\n",
    "        heights = [counts[int(b)] for b in BINS_MS]\n",
    "        ax.bar(range(len(BINS_MS)), heights)\n",
    "        ax.set_xticks(range(len(BINS_MS)))\n",
    "        ax.set_xticklabels([f\"{b}\" for b in BINS_MS])\n",
    "        ax.set_xlabel(\"Modal lag (ms)\")\n",
    "        ax.set_title(title)\n",
    "    axes[0].set_ylabel(f\"Count of robust edges (≥{int(thr*100)}%)\")\n",
    "    plt.tight_layout()\n",
    "    fig_out = FIGDIR / f\"lag_histograms_gauss_thr{int(thr*100)}.png\"\n",
    "    plt.savefig(fig_out, bbox_inches=\"tight\"); plt.close(fig)\n",
    "    print(\"Saved:\", fig_out)\n",
    "\n",
    "# Run for 50%, 70%, 90% (added 50% — logic unchanged)\n",
    "for thr, tag in [(0.50, \"thr50\"), (0.70, \"thr70\"), (0.90, \"thr90\")]:\n",
    "    summarize_and_plot(thr, tag)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebd8fcb0-36d6-41e4-8857-8e4629306d17",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
